{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37fc4f3b",
   "metadata": {
    "papermill": {
     "duration": 0.024577,
     "end_time": "2022-02-02T05:45:51.586634",
     "exception": false,
     "start_time": "2022-02-02T05:45:51.562057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "This work consists of two parts:     \n",
    "    <ul>\n",
    "        <li> PART 1 - UTILIZE YOLOv5 MODEL!!</li>\n",
    "        <li> PART 2 - LARGER RESOLUTION INFERENCE!!</a></li>\n",
    "    </ul>\n",
    "    \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<strong>Feel free to use it and enjoy!\n",
    "    I really appreciate if you upvote this notebook. Thank you! </strong>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bbf4e2",
   "metadata": {
    "papermill": {
     "duration": 0.024269,
     "end_time": "2022-02-02T05:45:51.634321",
     "exception": false,
     "start_time": "2022-02-02T05:45:51.610052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# [Tensorflow - Help Protect the Great Barrier Reef](https://www.kaggle.com/c/tensorflow-great-barrier-reef)\n",
    "> Detect crown-of-thorns starfish in underwater image data\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/31703/logos/header.png?t=2021-10-29-00-30-04\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3750735",
   "metadata": {
    "papermill": {
     "duration": 0.024137,
     "end_time": "2022-02-02T05:45:51.683176",
     "exception": false,
     "start_time": "2022-02-02T05:45:51.659039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸ“š Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d54c72",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-02T05:45:51.764185Z",
     "iopub.status.busy": "2022-02-02T05:45:51.763224Z",
     "iopub.status.idle": "2022-02-02T05:45:53.360447Z",
     "shell.execute_reply": "2022-02-02T05:45:53.359792Z",
     "shell.execute_reply.started": "2022-02-02T05:42:35.342696Z"
    },
    "papermill": {
     "duration": 1.653461,
     "end_time": "2022-02-02T05:45:53.360595",
     "exception": false,
     "start_time": "2022-02-02T05:45:51.707134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import shutil\n",
    "import sys\n",
    "sys.path.append('input/tensorflow-great-barrier-reef')\n",
    "import torch\n",
    "from PIL import Image\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8823536",
   "metadata": {
    "papermill": {
     "duration": 0.020566,
     "end_time": "2022-02-02T05:45:53.402110",
     "exception": false,
     "start_time": "2022-02-02T05:45:53.381544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸ“Œ Key-Points\n",
    "* One have to submit prediction using the provided **python time-series API**, which makes this competition different from previous Object Detection Competitions.\n",
    "* Each prediction row needs to include all bounding boxes for the image. Submission is format seems also **COCO** which means `[x_min, y_min, width, height]`\n",
    "* Copmetition metric `F2` tolerates some false positives(FP) in order to ensure very few starfish are missed. Which means tackling **false negatives(FN)** is more important than false positives(FP). \n",
    "$$F2 = 5 \\cdot \\frac{precision \\cdot recall}{4\\cdot precision + recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d5b32f",
   "metadata": {
    "papermill": {
     "duration": 0.020444,
     "end_time": "2022-02-02T05:45:53.443453",
     "exception": false,
     "start_time": "2022-02-02T05:45:53.423009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Please Upvote if you find this Helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca931b77",
   "metadata": {
    "papermill": {
     "duration": 0.020349,
     "end_time": "2022-02-02T05:45:53.484388",
     "exception": false,
     "start_time": "2022-02-02T05:45:53.464039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸ“– Meta Data\n",
    "* `train_images/` - Folder containing training set photos of the form `video_{video_id}/{video_frame}.jpg`.\n",
    "\n",
    "* `[train/test].csv` - Metadata for the images. As with other test files, most of the test metadata data is only available to your notebook upon submission. Just the first few rows available for download.\n",
    "\n",
    "* `video_id` - ID number of the video the image was part of. The video ids are not meaningfully ordered.\n",
    "* `video_frame` - The frame number of the image within the video. Expect to see occasional gaps in the frame number from when the diver surfaced.\n",
    "* `sequence` - ID of a gap-free subset of a given video. The sequence ids are not meaningfully ordered.\n",
    "* `sequence_frame` - The frame number within a given sequence.\n",
    "* `image_id` - ID code for the image, in the format `{video_id}-{video_frame}`\n",
    "* `annotations` - The bounding boxes of any starfish detections in a string format that can be evaluated directly with Python. Does not use the same format as the predictions you will submit. Not available in test.csv. A bounding box is described by the pixel coordinate `(x_min, y_min)` of its lower left corner within the image together with its `width` and `height` in pixels --> (COCO format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a94ac1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T05:45:53.531507Z",
     "iopub.status.busy": "2022-02-02T05:45:53.530725Z",
     "iopub.status.idle": "2022-02-02T05:45:53.533253Z",
     "shell.execute_reply": "2022-02-02T05:45:53.532837Z",
     "shell.execute_reply.started": "2022-02-02T05:42:37.190344Z"
    },
    "papermill": {
     "duration": 0.028332,
     "end_time": "2022-02-02T05:45:53.533368",
     "exception": false,
     "start_time": "2022-02-02T05:45:53.505036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROOT_DIR  = 'input/tensorflow-great-barrier-reef/'\n",
    "weights_path = 'input/yolov5-1920-4/'   # ../input/yolov5-1920-4/best.pt\n",
    "CKPT_PATH = weights_path + '/best.pt'\n",
    "IMG_SIZE  = 10000#int(2000*3)  # \n",
    "CONF      = 0.275     # 1920*3 + conf-0.3\n",
    "IOU       = 0.2\n",
    "AUGMENT   = True     # TTA will run for an hour, will gain improvement\n",
    "TRACKING  = False\n",
    "FDA_aug   = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002dceca",
   "metadata": {
    "papermill": {
     "duration": 0.020385,
     "end_time": "2022-02-02T05:45:53.574566",
     "exception": false,
     "start_time": "2022-02-02T05:45:53.554181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3b5cbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T05:45:53.676423Z",
     "iopub.status.busy": "2022-02-02T05:45:53.665315Z",
     "iopub.status.idle": "2022-02-02T05:47:09.439076Z",
     "shell.execute_reply": "2022-02-02T05:47:09.439541Z",
     "shell.execute_reply.started": "2022-02-02T05:42:37.201335Z"
    },
    "papermill": {
     "duration": 75.844234,
     "end_time": "2022-02-02T05:47:09.439736",
     "exception": false,
     "start_time": "2022-02-02T05:45:53.595502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if TRACKING:\n",
    "# Dependencies\n",
    "%cd input/norfair031py3/\n",
    "!pip install commonmark-0.9.1-py2.py3-none-any.whl -f ./ --no-index\n",
    "!pip install rich-9.13.0-py3-none-any.whl\n",
    "\n",
    "!mkdir working/tmp\n",
    "!cp -r input/norfair031py3/filterpy-1.4.5/filterpy-1.4.5/ /kaggle/working/tmp/\n",
    "%cd working/tmp/filterpy-1.4.5/\n",
    "!pip install .\n",
    "!rm -rf working/tmp\n",
    "\n",
    "%cd input/norfair031py3/\n",
    "!pip install norfair-0.3.1-py3-none-any.whl -f ./ --no-index\n",
    "%cd working/\n",
    "\n",
    "from norfair import Detection, Tracker\n",
    "\n",
    "def to_norfair(detects, frame_id):\n",
    "    result = []\n",
    "    for x_min, y_min, x_max, y_max, score in detects:\n",
    "        xc, yc = (x_min + x_max) / 2, (y_min + y_max) / 2\n",
    "        w, h = x_max - x_min, y_max - y_min\n",
    "        result.append(Detection(points=np.array([xc, yc]), scores=np.array([score]), data=np.array([w, h, frame_id])))\n",
    "\n",
    "    return result\n",
    "\n",
    "# Euclidean distance function to match detections on this frame with tracked_objects from previous frames\n",
    "def euclidean_distance(detection, tracked_object):\n",
    "    return np.linalg.norm(detection.points - tracked_object.estimate)\n",
    "\n",
    "tracker = Tracker(\n",
    "    distance_function=euclidean_distance, \n",
    "    distance_threshold=30,\n",
    "    hit_inertia_min=3,\n",
    "    hit_inertia_max=6,\n",
    "    initialization_delay=1,\n",
    ")\n",
    "frame_id = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba1a567",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T05:47:09.499534Z",
     "iopub.status.busy": "2022-02-02T05:47:09.498669Z",
     "iopub.status.idle": "2022-02-02T05:47:09.500449Z",
     "shell.execute_reply": "2022-02-02T05:47:09.500916Z",
     "shell.execute_reply.started": "2022-02-02T05:43:52.694258Z"
    },
    "papermill": {
     "duration": 0.033996,
     "end_time": "2022-02-02T05:47:09.501059",
     "exception": false,
     "start_time": "2022-02-02T05:47:09.467063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_path(row):\n",
    "    row['image_path'] = f'{ROOT_DIR}/train_images/video_{row.video_id}/{row.video_frame}.jpg'\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38459607",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T05:47:09.559537Z",
     "iopub.status.busy": "2022-02-02T05:47:09.558959Z",
     "iopub.status.idle": "2022-02-02T05:47:09.562492Z",
     "shell.execute_reply": "2022-02-02T05:47:09.562909Z",
     "shell.execute_reply.started": "2022-02-02T05:44:42.324613Z"
    },
    "papermill": {
     "duration": 0.035076,
     "end_time": "2022-02-02T05:47:09.563058",
     "exception": false,
     "start_time": "2022-02-02T05:47:09.527982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " # Train Data\n",
    "# df = pd.read_csv(f'{ROOT_DIR}/train.csv')\n",
    "# df = df.progress_apply(get_path, axis=1)\n",
    "# df['annotations'] = df['annotations'].progress_apply(lambda x: ast.literal_eval(x))\n",
    "# display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd407ac",
   "metadata": {
    "papermill": {
     "duration": 0.026686,
     "end_time": "2022-02-02T05:47:09.616740",
     "exception": false,
     "start_time": "2022-02-02T05:47:09.590054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Number of BBoxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964bacba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T05:47:09.675311Z",
     "iopub.status.busy": "2022-02-02T05:47:09.674439Z",
     "iopub.status.idle": "2022-02-02T05:47:09.676436Z",
     "shell.execute_reply": "2022-02-02T05:47:09.676899Z",
     "shell.execute_reply.started": "2022-02-02T05:44:43.759301Z"
    },
    "papermill": {
     "duration": 0.033114,
     "end_time": "2022-02-02T05:47:09.677049",
     "exception": false,
     "start_time": "2022-02-02T05:47:09.643935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df['num_bbox'] = df['annotations'].progress_apply(lambda x: len(x))\n",
    "# data = (df.num_bbox>0).value_counts()/len(df)*100\n",
    "# print(f\"No BBox: {data[0]:0.2f}% | With BBox: {data[1]:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9696373a",
   "metadata": {
    "papermill": {
     "duration": 0.031307,
     "end_time": "2022-02-02T05:47:09.735553",
     "exception": false,
     "start_time": "2022-02-02T05:47:09.704246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸ”¨ Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3d2917",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T05:47:09.798437Z",
     "iopub.status.busy": "2022-02-02T05:47:09.797552Z",
     "iopub.status.idle": "2022-02-02T05:47:09.799751Z",
     "shell.execute_reply": "2022-02-02T05:47:09.800213Z",
     "shell.execute_reply.started": "2022-02-02T05:44:44.848312Z"
    },
    "papermill": {
     "duration": 0.034885,
     "end_time": "2022-02-02T05:47:09.800372",
     "exception": false,
     "start_time": "2022-02-02T05:47:09.765487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check https://github.com/awsaf49/bbox for source code of following utility functions\n",
    "# from bbox.utils import coco2yolo, coco2voc, voc2yolo\n",
    "# from bbox.utils import draw_bboxes, load_image\n",
    "# from bbox.utils import clip_bbox, str2annot, annot2str\n",
    "\n",
    "# def get_bbox(annots):\n",
    "#     bboxes = [list(annot.values()) for annot in annots]\n",
    "#     return bboxes\n",
    "\n",
    "# def get_imgsize(row):\n",
    "#     row['width'], row['height'] = imagesize.get(row['image_path'])\n",
    "#     return row\n",
    "\n",
    "# np.random.seed(32)\n",
    "# colors = [(np.random.randint(255), np.random.randint(255), np.random.randint(255))\\\n",
    "#           for idx in range(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40090cc",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-02T05:47:09.895645Z",
     "iopub.status.busy": "2022-02-02T05:47:09.892248Z",
     "iopub.status.idle": "2022-02-02T05:47:09.898155Z",
     "shell.execute_reply": "2022-02-02T05:47:09.897687Z",
     "shell.execute_reply.started": "2022-02-02T05:44:45.487448Z"
    },
    "papermill": {
     "duration": 0.069963,
     "end_time": "2022-02-02T05:47:09.898280",
     "exception": false,
     "start_time": "2022-02-02T05:47:09.828317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def voc2yolo(bboxes, image_height=720, image_width=1280):\n",
    "    \"\"\"\n",
    "    voc  => [x1, y1, x2, y1]\n",
    "    yolo => [xmid, ymid, w, h] (normalized)\n",
    "    \"\"\"\n",
    "    \n",
    "    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
    "    \n",
    "    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]/ image_width\n",
    "    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]/ image_height\n",
    "    \n",
    "    w = bboxes[..., 2] - bboxes[..., 0]\n",
    "    h = bboxes[..., 3] - bboxes[..., 1]\n",
    "    \n",
    "    bboxes[..., 0] = bboxes[..., 0] + w/2\n",
    "    bboxes[..., 1] = bboxes[..., 1] + h/2\n",
    "    bboxes[..., 2] = w\n",
    "    bboxes[..., 3] = h\n",
    "    \n",
    "    return bboxes\n",
    "\n",
    "def yolo2voc(bboxes, image_height=720, image_width=1280):\n",
    "    \"\"\"\n",
    "    yolo => [xmid, ymid, w, h] (normalized)\n",
    "    voc  => [x1, y1, x2, y1]\n",
    "    \n",
    "    \"\"\" \n",
    "    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
    "    \n",
    "    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n",
    "    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n",
    "    \n",
    "    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n",
    "    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n",
    "    \n",
    "    return bboxes\n",
    "\n",
    "def coco2yolo(bboxes, image_height=720, image_width=1280):\n",
    "    \"\"\"\n",
    "    coco => [xmin, ymin, w, h]\n",
    "    yolo => [xmid, ymid, w, h] (normalized)\n",
    "    \"\"\"\n",
    "    \n",
    "    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
    "    \n",
    "    # normolizinig\n",
    "    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]/ image_width\n",
    "    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]/ image_height\n",
    "    \n",
    "    # converstion (xmin, ymin) => (xmid, ymid)\n",
    "    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]/2\n",
    "    \n",
    "    return bboxes\n",
    "\n",
    "def yolo2coco(bboxes, image_height=720, image_width=1280):\n",
    "    \"\"\"\n",
    "    yolo => [xmid, ymid, w, h] (normalized)\n",
    "    coco => [xmin, ymin, w, h]\n",
    "    \n",
    "    \"\"\" \n",
    "    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
    "    \n",
    "    # denormalizing\n",
    "    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]* image_width\n",
    "    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]* image_height\n",
    "    \n",
    "    # converstion (xmid, ymid) => (xmin, ymin) \n",
    "    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n",
    "    \n",
    "    return bboxes\n",
    "\n",
    "def voc2coco(bboxes, image_height=720, image_width=1280):\n",
    "    bboxes  = voc2yolo(bboxes, image_height, image_width)\n",
    "    bboxes  = yolo2coco(bboxes, image_height, image_width)\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "def load_image(image_path):\n",
    "    return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "def plot_one_box(x, img, color=None, label=None, line_thickness=None):\n",
    "    # Plots one bounding box on image img\n",
    "    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n",
    "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
    "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
    "    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "    if label:\n",
    "        tf = max(tl - 1, 1)  # font thickness\n",
    "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
    "        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "\n",
    "def draw_bboxes(img, bboxes, classes, class_ids, colors = None, show_classes = None, bbox_format = 'yolo', class_name = False, line_thickness = 2):  \n",
    "     \n",
    "    image = img.copy()\n",
    "    show_classes = classes if show_classes is None else show_classes\n",
    "    colors = (0, 255 ,0) if colors is None else colors\n",
    "    \n",
    "    if bbox_format == 'yolo':\n",
    "        \n",
    "        for idx in range(len(bboxes)):  \n",
    "            \n",
    "            bbox  = bboxes[idx]\n",
    "            cls   = classes[idx]\n",
    "            cls_id = class_ids[idx]\n",
    "            color = colors[cls_id] if type(colors) is list else colors\n",
    "            \n",
    "            if cls in show_classes:\n",
    "            \n",
    "                x1 = round(float(bbox[0])*image.shape[1])\n",
    "                y1 = round(float(bbox[1])*image.shape[0])\n",
    "                w  = round(float(bbox[2])*image.shape[1]/2) #w/2 \n",
    "                h  = round(float(bbox[3])*image.shape[0]/2)\n",
    "\n",
    "                voc_bbox = (x1-w, y1-h, x1+w, y1+h)\n",
    "                plot_one_box(voc_bbox, \n",
    "                             image,\n",
    "                             color = color,\n",
    "                             label = cls if class_name else str(get_label(cls)),\n",
    "                             line_thickness = line_thickness)\n",
    "            \n",
    "    elif bbox_format == 'coco':\n",
    "        \n",
    "        for idx in range(len(bboxes)):  \n",
    "            \n",
    "            bbox  = bboxes[idx]\n",
    "            cls   = classes[idx]\n",
    "            cls_id = class_ids[idx]\n",
    "            color = colors[cls_id] if type(colors) is list else colors\n",
    "            \n",
    "            if cls in show_classes:            \n",
    "                x1 = int(round(bbox[0]))\n",
    "                y1 = int(round(bbox[1]))\n",
    "                w  = int(round(bbox[2]))\n",
    "                h  = int(round(bbox[3]))\n",
    "\n",
    "                voc_bbox = (x1, y1, x1+w, y1+h)\n",
    "                plot_one_box(voc_bbox, \n",
    "                             image,\n",
    "                             color = color,\n",
    "                             label = cls if class_name else str(cls_id),\n",
    "                             line_thickness = line_thickness)\n",
    "\n",
    "    elif bbox_format == 'voc_pascal':\n",
    "        \n",
    "        for idx in range(len(bboxes)):  \n",
    "            \n",
    "            bbox  = bboxes[idx]\n",
    "            cls   = classes[idx]\n",
    "            cls_id = class_ids[idx]\n",
    "            color = colors[cls_id] if type(colors) is list else colors\n",
    "            \n",
    "            if cls in show_classes: \n",
    "                x1 = int(round(bbox[0]))\n",
    "                y1 = int(round(bbox[1]))\n",
    "                x2 = int(round(bbox[2]))\n",
    "                y2 = int(round(bbox[3]))\n",
    "                voc_bbox = (x1, y1, x2, y2)\n",
    "                plot_one_box(voc_bbox, \n",
    "                             image,\n",
    "                             color = color,\n",
    "                             label = cls if class_name else str(cls_id),\n",
    "                             line_thickness = line_thickness)\n",
    "    else:\n",
    "        raise ValueError('wrong bbox format')\n",
    "\n",
    "    return image\n",
    "\n",
    "def get_bbox(annots):\n",
    "    bboxes = [list(annot.values()) for annot in annots]\n",
    "    return bboxes\n",
    "\n",
    "def get_imgsize(row):\n",
    "    row['width'], row['height'] = imagesize.get(row['image_path'])\n",
    "    return row\n",
    "\n",
    "np.random.seed(32)\n",
    "colors = [(np.random.randint(255), np.random.randint(255), np.random.randint(255))\\\n",
    "          for idx in range(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4953533f",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-02T05:47:09.958822Z",
     "iopub.status.busy": "2022-02-02T05:47:09.958049Z",
     "iopub.status.idle": "2022-02-02T05:47:11.397181Z",
     "shell.execute_reply": "2022-02-02T05:47:11.396646Z",
     "shell.execute_reply.started": "2022-02-02T05:44:45.901901Z"
    },
    "papermill": {
     "duration": 1.471524,
     "end_time": "2022-02-02T05:47:11.397314",
     "exception": false,
     "start_time": "2022-02-02T05:47:09.925790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!sudo mkdir -p /root/.config/Ultralytics\n",
    "!sudo cp input/yolov5-font/Arial.ttf /root/.config/Ultralytics/\n",
    "!789789789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5efef57",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-02T05:47:11.459539Z",
     "iopub.status.busy": "2022-02-02T05:47:11.458601Z",
     "iopub.status.idle": "2022-02-02T05:47:11.460486Z",
     "shell.execute_reply": "2022-02-02T05:47:11.460981Z",
     "shell.execute_reply.started": "2022-02-02T05:44:47.254034Z"
    },
    "papermill": {
     "duration": 0.036603,
     "end_time": "2022-02-02T05:47:11.461128",
     "exception": false,
     "start_time": "2022-02-02T05:47:11.424525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(ckpt_path, conf=0.25, iou=0.50):\n",
    "    model = torch.hub.load('input/d/awsaf49/yolov5-lib-ds',\n",
    "                           'custom',\n",
    "                           path=ckpt_path,\n",
    "                           source='local',\n",
    "                           force_reload=True)  # local repo\n",
    "    model.conf = conf  # NMS confidence threshold\n",
    "    model.iou  = iou   # NMS IoU threshold\n",
    "    model.classes = None   # (optional list) filter by class, i.e. = [0, 15, 16] for persons, cats and dogs\n",
    "    model.multi_label = False  # NMS multiple labels per box\n",
    "    model.max_det = 1000  # maximum number of detections per image\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6178ad6",
   "metadata": {
    "papermill": {
     "duration": 0.027032,
     "end_time": "2022-02-02T05:47:11.516010",
     "exception": false,
     "start_time": "2022-02-02T05:47:11.488978",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸ”­ Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd2e015",
   "metadata": {
    "papermill": {
     "duration": 0.026743,
     "end_time": "2022-02-02T05:47:11.570456",
     "exception": false,
     "start_time": "2022-02-02T05:47:11.543713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad5d074",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-02T05:47:11.636464Z",
     "iopub.status.busy": "2022-02-02T05:47:11.635450Z",
     "iopub.status.idle": "2022-02-02T05:47:11.637231Z",
     "shell.execute_reply": "2022-02-02T05:47:11.637633Z",
     "shell.execute_reply.started": "2022-02-02T05:44:48.416858Z"
    },
    "papermill": {
     "duration": 0.039935,
     "end_time": "2022-02-02T05:47:11.637786",
     "exception": false,
     "start_time": "2022-02-02T05:47:11.597851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, img, size=768, augment=False):\n",
    "    height, width = img.shape[:2]\n",
    "    results = model(img, size=size, augment=augment)  # custom inference size\n",
    "    preds   = results.pandas().xyxy[0]\n",
    "    bboxes  = preds[['xmin','ymin','xmax','ymax']].values\n",
    "    if len(bboxes):\n",
    "        bboxes  = voc2coco(bboxes,height,width).astype(int)\n",
    "        confs   = preds.confidence.values\n",
    "        return bboxes, confs\n",
    "    else:\n",
    "        return [],[]\n",
    "    \n",
    "def format_prediction(bboxes, confs):\n",
    "    annot = ''\n",
    "    if len(bboxes)>0:\n",
    "        for idx in range(len(bboxes)):\n",
    "            xmin, ymin, w, h = bboxes[idx]\n",
    "            conf             = confs[idx]\n",
    "            annot += f'{conf} {xmin} {ymin} {w} {h}'\n",
    "            annot +=' '\n",
    "        annot = annot.strip(' ')\n",
    "    return annot\n",
    "\n",
    "def show_img(img, bboxes, bbox_format='yolo'):\n",
    "    names  = ['starfish']*len(bboxes)\n",
    "    labels = [0]*len(bboxes)\n",
    "    img    = draw_bboxes(img = img,\n",
    "                           bboxes = bboxes, \n",
    "                           classes = names,\n",
    "                           class_ids = labels,\n",
    "                           class_name = True, \n",
    "                           colors = colors, \n",
    "                           bbox_format = bbox_format,\n",
    "                           line_thickness = 2)\n",
    "    return Image.fromarray(img).resize((800, 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c03218",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T05:47:11.695500Z",
     "iopub.status.busy": "2022-02-02T05:47:11.694669Z",
     "iopub.status.idle": "2022-02-02T05:47:11.704235Z",
     "shell.execute_reply": "2022-02-02T05:47:11.703754Z",
     "shell.execute_reply.started": "2022-02-02T05:44:48.798303Z"
    },
    "papermill": {
     "duration": 0.039694,
     "end_time": "2022-02-02T05:47:11.704350",
     "exception": false,
     "start_time": "2022-02-02T05:47:11.664656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tracking_function(tracker, frame_id, bboxes, scores):\n",
    "    \n",
    "    detects = []\n",
    "    predictions = []\n",
    "    \n",
    "    if len(scores)>0:\n",
    "        for i in range(len(bboxes)):\n",
    "            box = bboxes[i]\n",
    "            score = scores[i]\n",
    "            x_min = int(box[0])\n",
    "            y_min = int(box[1])\n",
    "            bbox_width = int(box[2])\n",
    "            bbox_height = int(box[3])\n",
    "            detects.append([x_min, y_min, x_min+bbox_width, y_min+bbox_height, score])\n",
    "            predictions.append('{:.2f} {} {} {} {}'.format(score, x_min, y_min, bbox_width, bbox_height))\n",
    "#             print(predictions[:-1])\n",
    "    # Update tracks using detects from current frame\n",
    "    tracked_objects = tracker.update(detections=to_norfair(detects, frame_id))\n",
    "    for tobj in tracked_objects:\n",
    "        bbox_width, bbox_height, last_detected_frame_id = tobj.last_detection.data\n",
    "        if last_detected_frame_id == frame_id:  # Skip objects that were detected on current frame\n",
    "            continue\n",
    "        # Add objects that have no detections on current frame to predictions\n",
    "        xc, yc = tobj.estimate[0]\n",
    "        x_min, y_min = int(round(xc - bbox_width / 2)), int(round(yc - bbox_height / 2))\n",
    "        score = tobj.last_detection.scores[0]\n",
    "\n",
    "        predictions.append('{:.2f} {} {} {} {}'.format(score, x_min, y_min, bbox_width, bbox_height))\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e3a614",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T05:47:11.782731Z",
     "iopub.status.busy": "2022-02-02T05:47:11.781783Z",
     "iopub.status.idle": "2022-02-02T05:47:11.783683Z",
     "shell.execute_reply": "2022-02-02T05:47:11.784322Z",
     "shell.execute_reply.started": "2022-02-02T05:44:49.147099Z"
    },
    "papermill": {
     "duration": 0.042643,
     "end_time": "2022-02-02T05:47:11.784477",
     "exception": false,
     "start_time": "2022-02-02T05:47:11.741834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_bbox(anno):\n",
    "    for idx, a in enumerate(anno):\n",
    "        try:\n",
    "            anno[idx] = [a['x'], a['y'], a['width'], a['height']]\n",
    "        except:\n",
    "            break\n",
    "    return anno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a00ad6",
   "metadata": {
    "papermill": {
     "duration": 0.027584,
     "end_time": "2022-02-02T05:47:11.842034",
     "exception": false,
     "start_time": "2022-02-02T05:47:11.814450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run Inference on **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86400663",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T05:47:11.908428Z",
     "iopub.status.busy": "2022-02-02T05:47:11.901108Z",
     "iopub.status.idle": "2022-02-02T05:47:12.557587Z",
     "shell.execute_reply": "2022-02-02T05:47:12.557087Z",
     "shell.execute_reply.started": "2022-02-02T05:44:49.886618Z"
    },
    "papermill": {
     "duration": 0.688554,
     "end_time": "2022-02-02T05:47:12.557751",
     "exception": false,
     "start_time": "2022-02-02T05:47:11.869197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp input/yolov5-font/Arial.ttf /root/.config/Ultralytics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ee857a",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-02T05:47:12.618415Z",
     "iopub.status.busy": "2022-02-02T05:47:12.617517Z",
     "iopub.status.idle": "2022-02-02T05:47:12.620112Z",
     "shell.execute_reply": "2022-02-02T05:47:12.619646Z",
     "shell.execute_reply.started": "2022-02-02T05:44:50.566514Z"
    },
    "papermill": {
     "duration": 0.035104,
     "end_time": "2022-02-02T05:47:12.620228",
     "exception": false,
     "start_time": "2022-02-02T05:47:12.585124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(\"Use TRACKING...\")    \n",
    "# tracker = Tracker(\n",
    "# distance_function=euclidean_distance, \n",
    "# distance_threshold=30,\n",
    "# hit_inertia_min=3,\n",
    "# hit_inertia_max=6,\n",
    "# initialization_delay=1,\n",
    "# )\n",
    "\n",
    "# model = load_model(CKPT_PATH, conf=CONF, iou=IOU)\n",
    "# image_paths = df[df.num_bbox>1].sample(100)\n",
    "# frame_id = 0\n",
    "# for idx, path in enumerate(image_paths.image_path.tolist()):\n",
    "#     img = cv2.imread(path)[...,::-1]\n",
    "#     if FDA_aug:\n",
    "#         img = FDA_trans(image=img)['image']\n",
    "#     bboxes, confis = predict(model, img, size=IMG_SIZE, augment=AUGMENT)\n",
    "#     predict_box = tracking_function(tracker, frame_id, bboxes, confis)\n",
    "#\n",
    "#     if len(predict_box)>0:\n",
    "#         box = [list(map(int,box.split(' ')[1:])) for box in predict_box]\n",
    "#     else:\n",
    "#         box = []\n",
    "#     display(show_img(img, box, bbox_format='coco'))\n",
    "#     display(show_img(img, bboxes, bbox_format='coco'))  # Predict\n",
    "#     display(show_img(img, extract_bbox(image_paths.iloc[idx].annotations), bbox_format='coco'))\n",
    "#     if idx>3:\n",
    "#         break\n",
    "#     frame_id += 1\n",
    "    \n",
    "# # print(\"Not Use TRACKING...\")    \n",
    "# # model = load_model(CKPT_PATH, conf=CONF, iou=IOU)\n",
    "\n",
    "# # # d = df[df.num_bbox>1].sample(100)\n",
    "\n",
    "# # for idx, path in enumerate(image_paths.image_path.tolist()):\n",
    "# #     img = cv2.imread(path)[...,::-1]\n",
    "# #     bboxes, confis = predict(model, img, size=IMG_SIZE, augment=AUGMENT)\n",
    "# # #     print(bboxes, extract_bbox(d.iloc[idx].annotations), confis)\n",
    "\n",
    "    \n",
    "# #     display(show_img(img, extract_bbox(image_paths.iloc[idx].annotations), bbox_format='coco'))\n",
    "\n",
    "# #     if idx>3:\n",
    "# #         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6994f3fc",
   "metadata": {
    "papermill": {
     "duration": 0.027138,
     "end_time": "2022-02-02T05:47:12.674294",
     "exception": false,
     "start_time": "2022-02-02T05:47:12.647156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Init `Env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ec8ed",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-02T05:47:12.733424Z",
     "iopub.status.busy": "2022-02-02T05:47:12.732776Z",
     "iopub.status.idle": "2022-02-02T05:47:12.758352Z",
     "shell.execute_reply": "2022-02-02T05:47:12.757825Z",
     "shell.execute_reply.started": "2022-02-02T05:44:51.016958Z"
    },
    "papermill": {
     "duration": 0.057201,
     "end_time": "2022-02-02T05:47:12.758470",
     "exception": false,
     "start_time": "2022-02-02T05:47:12.701269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import greatbarrierreef\n",
    "env = greatbarrierreef.make_env()# initialize the environment\n",
    "iter_test = env.iter_test()      # an iterator which loops over the test set and sample submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4faf247",
   "metadata": {
    "papermill": {
     "duration": 0.02823,
     "end_time": "2022-02-02T05:47:12.814355",
     "exception": false,
     "start_time": "2022-02-02T05:47:12.786125",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run Inference on **Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a455b59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T05:47:12.878619Z",
     "iopub.status.busy": "2022-02-02T05:47:12.875664Z",
     "iopub.status.idle": "2022-02-02T05:47:13.529270Z",
     "shell.execute_reply": "2022-02-02T05:47:13.529829Z",
     "shell.execute_reply.started": "2022-02-02T05:44:52.079035Z"
    },
    "papermill": {
     "duration": 0.68847,
     "end_time": "2022-02-02T05:47:13.530078",
     "exception": false,
     "start_time": "2022-02-02T05:47:12.841608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d81705",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-02T05:47:13.597377Z",
     "iopub.status.busy": "2022-02-02T05:47:13.596771Z",
     "iopub.status.idle": "2022-02-02T05:47:37.719970Z",
     "shell.execute_reply": "2022-02-02T05:47:37.718752Z",
     "shell.execute_reply.started": "2022-02-02T05:44:52.877806Z"
    },
    "papermill": {
     "duration": 24.162145,
     "end_time": "2022-02-02T05:47:37.720188",
     "exception": false,
     "start_time": "2022-02-02T05:47:13.558043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRACKING:\n",
    "    tracker = Tracker(\n",
    "    distance_function=euclidean_distance, \n",
    "    distance_threshold=30,\n",
    "    hit_inertia_min=3,\n",
    "    hit_inertia_max=6,\n",
    "    initialization_delay=1,\n",
    ")\n",
    "\n",
    "    model = load_model(CKPT_PATH, conf=CONF, iou=IOU)\n",
    "\n",
    "    frame_id =0\n",
    "    for idx, (img, pred_df) in enumerate(tqdm(iter_test)):\n",
    "        if FDA_aug:\n",
    "            img = FDA_trans(image=img)['image']\n",
    "        bboxes, confs  = predict(model, img, size=IMG_SIZE, augment=AUGMENT)\n",
    "\n",
    "        predictions = tracking_function(tracker, frame_id, bboxes, confs)\n",
    "\n",
    "        prediction_str = ' '.join(predictions)\n",
    "        pred_df['annotations'] = prediction_str\n",
    "        env.predict(pred_df)\n",
    "        if frame_id < 3:\n",
    "            if len(predictions)>0:\n",
    "                box = [list(map(int,box.split(' ')[1:])) for box in predictions]\n",
    "            else:\n",
    "                box = []\n",
    "            display(show_img(img, box, bbox_format='coco'))\n",
    "    #     print('Prediction:', pred_df)\n",
    "        frame_id += 1\n",
    "\n",
    "else:\n",
    "    model = load_model(CKPT_PATH, conf=CONF, iou=IOU)\n",
    "    for idx, (img, pred_df) in enumerate(tqdm(iter_test)):\n",
    "        bboxes, confs  = predict(model, img, size=IMG_SIZE, augment=AUGMENT)\n",
    "        annot          = format_prediction(bboxes, confs)\n",
    "        pred_df['annotations'] = annot\n",
    "        env.predict(pred_df)\n",
    "        if idx<3:\n",
    "            display(show_img(img, bboxes, bbox_format='coco'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82447031",
   "metadata": {
    "papermill": {
     "duration": 0.083954,
     "end_time": "2022-02-02T05:47:37.887959",
     "exception": false,
     "start_time": "2022-02-02T05:47:37.804005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸ‘€ Check Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f46a4e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T05:47:38.061794Z",
     "iopub.status.busy": "2022-02-02T05:47:38.061204Z",
     "iopub.status.idle": "2022-02-02T05:47:38.071271Z",
     "shell.execute_reply": "2022-02-02T05:47:38.071649Z",
     "shell.execute_reply.started": "2022-02-02T05:45:17.216786Z"
    },
    "papermill": {
     "duration": 0.100659,
     "end_time": "2022-02-02T05:47:38.071813",
     "exception": false,
     "start_time": "2022-02-02T05:47:37.971154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('submission.csv')\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a317b43",
   "metadata": {
    "papermill": {
     "duration": 0.083553,
     "end_time": "2022-02-02T05:47:38.239337",
     "exception": false,
     "start_time": "2022-02-02T05:47:38.155784",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Please Upvote if you find this Helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d56450c",
   "metadata": {
    "papermill": {
     "duration": 0.088926,
     "end_time": "2022-02-02T05:47:38.412466",
     "exception": false,
     "start_time": "2022-02-02T05:47:38.323540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://www.pngall.com/wp-content/uploads/2018/04/Under-Construction-PNG-File.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 116.039683,
   "end_time": "2022-02-02T05:47:39.960615",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-02T05:45:43.920932",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "436e897e929e4155b7538fff1d20500d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "48ab3bb66c494248adbd84c30bf708e0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "55a2520db2d84ebd804c130e6954b300": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a0ebafd77d3542acba10579b74ed59d6",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_bdb0625872bd4d6bbe8a1be6752c766c",
       "value": ""
      }
     },
     "6b6acad319c74874b4919ac1ff942619": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_436e897e929e4155b7538fff1d20500d",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b290801e34044920aa986041b5e0ee5e",
       "value": 1
      }
     },
     "783b398c25484ccb86f89c4de6cb4750": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8b0f5a3d10b84fb3811494a4da719e32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ea460c7b934e46f09964ce9ee1bd1ef3",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_783b398c25484ccb86f89c4de6cb4750",
       "value": " 3/? [00:13&lt;00:00,  3.92s/it]"
      }
     },
     "a0ebafd77d3542acba10579b74ed59d6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a582f548e7c64b1999afc842866ca1f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_55a2520db2d84ebd804c130e6954b300",
        "IPY_MODEL_6b6acad319c74874b4919ac1ff942619",
        "IPY_MODEL_8b0f5a3d10b84fb3811494a4da719e32"
       ],
       "layout": "IPY_MODEL_48ab3bb66c494248adbd84c30bf708e0"
      }
     },
     "b290801e34044920aa986041b5e0ee5e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bdb0625872bd4d6bbe8a1be6752c766c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ea460c7b934e46f09964ce9ee1bd1ef3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
